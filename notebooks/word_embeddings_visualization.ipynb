{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Day 2: Exploring Word Embeddings with Word2Vec and GloVe\n",
    "In this notebook, we'll dive into understanding and visualizing word embeddings using popular models like Word2Vec and GloVe. We will also use PCA and t-SNE to explore and represent these embeddings in a way that anyone can grasp intuitively. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ What are Word Embeddings?\n",
    "- Word embeddings are vector representations of words in a continuous vector space where similar words have similar representations.\n",
    "- They capture semantic meaning, allowing us to find relationships like:\n",
    "  - `king - man + woman ‚âà queen`\n",
    "- Popular models include **Word2Vec** and **GloVe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mapi\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Loading Pre-trained Word Embeddings\n",
    "We'll use the **Google's Word2Vec** pre-trained model, which has been trained on a large corpus of text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Word2Vec pre-trained model\n",
    "model = api.load('word2vec-google-news-300')\n",
    "print('Model loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Finding Similar Words\n",
    "Let's find words similar to an input word using **cosine similarity**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get similar words\n",
    "def get_similar_words(word, top_n=10):\n",
    "    try:\n",
    "        similar_words = model.most_similar(word, topn=top_n)\n",
    "        return similar_words\n",
    "    except KeyError:\n",
    "        print(f'Word \"{word}\" not in vocabulary!')\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "similar_words = get_similar_words('king')\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Visualizing Word Embeddings with PCA\n",
    "Let's reduce the 300-dimensional vectors to 2D using **PCA** and visualize them with a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vectors and words\n",
    "words = [word for word, _ in similar_words]\n",
    "vectors = [model[word] for word in words]\n",
    "\n",
    "# Reduce dimensions with PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(vectors)\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "df_pca = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "df_pca['word'] = words\n",
    "\n",
    "# Plot using Seaborn\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='word', s=100)\n",
    "plt.title('PCA Visualization of Word Embeddings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Exploring Clusters with t-SNE\n",
    "Now, let's use **t-SNE** to visualize the embeddings and reveal clusters of similar words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensions with t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=15, n_iter=3000, random_state=42)\n",
    "tsne_result = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "df_tsne = pd.DataFrame(tsne_result, columns=['x', 'y'])\n",
    "df_tsne['word'] = words\n",
    "\n",
    "# Plot using Plotly\n",
    "fig = px.scatter(df_tsne, x='x', y='y', text='word', title='t-SNE Visualization of Word Embeddings')\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Conclusion\n",
    "- **Word2Vec** captures semantic relationships between words effectively.\n",
    "- **PCA** gives a quick, efficient 2D visualization.\n",
    "- **t-SNE** provides deeper insights into clusters of similar words.\n",
    "Play around with different words and see what you discover!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
